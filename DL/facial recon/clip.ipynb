{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6591,
     "status": "ok",
     "timestamp": 1766325975241,
     "user": {
      "displayName": "OUCHEN PRODS",
      "userId": "07694875544578408431"
     },
     "user_tz": -60
    },
    "id": "Y3v_1vquOjIY",
    "outputId": "933d922b-2384-41ed-91da-b47b04656cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.14)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ftfy\n",
      "Successfully installed ftfy-6.3.1\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-rqluir4r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-rqluir4r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (25.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.9.0+cpu)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.24.0+cpu)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->clip==1.0) (0.2.14)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2025.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clip==1.0) (3.0.3)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369549 sha256=400b668b09ee4cffb34002c25e7da9fef6a4d3061d1c399af51c0092ace857f4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ob968las/wheels/35/3e/df/3d24cbfb3b6a06f17a2bfd7d1138900d4365d9028aa8f6e92f\n",
      "Successfully built clip\n",
      "Installing collected packages: clip\n",
      "Successfully installed clip-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1766326953417,
     "user": {
      "displayName": "OUCHEN PRODS",
      "userId": "07694875544578408431"
     },
     "user_tz": -60
    },
    "id": "cB7K1gs3PKLi",
    "outputId": "8a89db96-916c-4021-dcbc-85169e53be25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-29 15:08:30--  https://content.presspage.com/uploads/2170/1920_face-new-675956.jpg?10000\n",
      "Resolving content.presspage.com (content.presspage.com)... 143.204.160.111, 143.204.160.81, 143.204.160.19, ...\n",
      "Connecting to content.presspage.com (content.presspage.com)|143.204.160.111|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 164847 (161K) [image/jpeg]\n",
      "Saving to: ‘image.jpg’\n",
      "\n",
      "image.jpg           100%[===================>] 160.98K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2025-12-29 15:08:30 (10.1 MB/s) - ‘image.jpg’ saved [164847/164847]\n",
      "\n",
      "--2025-12-29 15:08:30--  https://as2.ftcdn.net/jpg/01/41/14/71/1000_F_141147103_DMr5f66cIrRUpbyFOMmz4MsVC0gMeD5i.jpg\n",
      "Resolving as2.ftcdn.net (as2.ftcdn.net)... 151.101.1.91, 151.101.65.91, 151.101.129.91, ...\n",
      "Connecting to as2.ftcdn.net (as2.ftcdn.net)|151.101.1.91|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 223668 (218K) [image/jpeg]\n",
      "Saving to: ‘image-2.jpg’\n",
      "\n",
      "image-2.jpg         100%[===================>] 218.43K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-12-29 15:08:30 (14.9 MB/s) - ‘image-2.jpg’ saved [223668/223668]\n",
      "\n",
      "--2025-12-29 15:08:30--  https://as1.ftcdn.net/v2/jpg/03/42/85/16/1000_F_342851651_BV9SYWnoTPSu3kq6e82zG7H8eEt20wd1.jpg\n",
      "Resolving as1.ftcdn.net (as1.ftcdn.net)... 151.101.1.91, 151.101.65.91, 151.101.129.91, ...\n",
      "Connecting to as1.ftcdn.net (as1.ftcdn.net)|151.101.1.91|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156160 (152K) [image/jpeg]\n",
      "Saving to: ‘image-3.jpg’\n",
      "\n",
      "image-3.jpg         100%[===================>] 152.50K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2025-12-29 15:08:30 (10.3 MB/s) - ‘image-3.jpg’ saved [156160/156160]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O image.jpg \"https://content.presspage.com/uploads/2170/1920_face-new-675956.jpg?10000\"\n",
    "!wget -O image-2.jpg \"https://as2.ftcdn.net/jpg/01/41/14/71/1000_F_141147103_DMr5f66cIrRUpbyFOMmz4MsVC0gMeD5i.jpg\"\n",
    "!wget -O image-3.jpg \"https://as1.ftcdn.net/v2/jpg/03/42/85/16/1000_F_342851651_BV9SYWnoTPSu3kq6e82zG7H8eEt20wd1.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2916,
     "status": "ok",
     "timestamp": 1766326960742,
     "user": {
      "displayName": "OUCHEN PRODS",
      "userId": "07694875544578408431"
     },
     "user_tz": -60
    },
    "id": "yVyxK66uO0I4",
    "outputId": "811beb88-f8c3-4870-8d3a-9a34a49ec0da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 189MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotion: a photo of a person feeling neutral [with a probability of 0.23908425867557526]\n"
     ]
    }
   ],
   "source": [
    "# @title TEST CLIP\n",
    "file_name = \"image-3.jpg\" # @param {\"type\":\"string\"}\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "image = preprocess(Image.open(file_name)).unsqueeze(0).to(device)\n",
    "\n",
    "emotions = [\n",
    "    \"happy\",\n",
    "    \"sad\",\n",
    "    \"angry\",\n",
    "    \"fear\",\n",
    "    \"surprised\",\n",
    "    \"disgust\",\n",
    "    \"neutral\"\n",
    "]\n",
    "\n",
    "prompts = [f\"a photo of a person feeling {e}\" for e in emotions]\n",
    "\n",
    "text = clip.tokenize(prompts).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu()\n",
    "\n",
    "pred_idx = probs.argmax(axis=-1)\n",
    "print(f\"Predicted emotion: {prompts[pred_idx]} [with a probability of {probs[:, pred_idx].item()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGtOlY6YQfZw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": [
    {
     "file_id": "1TAO9xRGQ-RZ2ASkd5z8v2K3LuGT_q3Oy",
     "timestamp": 1766327426354
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
